{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $§$ 1.2 Probability Theory\n",
    "\n",
    "> 概率论在人工智能上的应用主要是教我们如何设计算法用来计算或者估算概率论导出的表达式, 还有就是用概率论知识还理论化分析 AI 系统的行为.\n",
    "\n",
    "> 概率论能够使我们作出 **不确定声明(uncertainty statement)** 以及在不确定性存在情况下的推理, 而信息论使我们能够量化在概率分布中的不确定总量. \n",
    "\n",
    "> 推荐阅读 **Jaynes(2003)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $§$ 1.2.1\n",
    "\n",
    "不确定性的三大来源:\n",
    "\n",
    "* 被建模系统的 **内在随机性(inherent stochasticity)**\n",
    "* 不完整的观察(incomplete observability)\n",
    "* 不完整的建模\n",
    "\n",
    "很多情况下, 使用简单但是不确定的规则比复杂而确定(deterministic)的规则更加实用.\n",
    "\n",
    "早期的概率论是用来分析事件的频率, 并且这类事件都是可以(趋近于无限)重复发生的. 而如果是一个医生给一个病人看病并且告诉病人他有 40% 的概率患流感, 因为病人不能被复制, 所以这不是一个可重复事件. 在这种情况, 我们使用概率来表示 **信念度(degree of belief)**, 其中 1 表示病人肯定患有流感, 0 表示病人肯定没有患流感, 前者直接与事件发生的比率(rate)相关, 被称为 **频率派概率(frequentist probability)**, 而后者涉及到 **确定度水平(qualitative levels of certainty)**, 被称为 **贝叶斯概率(Bayesian probability)**. 如果要列出一些关于不确定性(uncertainty)的常识推理(common sense reasons)中我们希望要有的性质(property), 要满足这些性质的唯一方法就是将贝叶斯概率的行为和概率派概率完全等同. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $§$ 1.2.2 随机变量(Random Variables)\n",
    "\n",
    "**随机变量** 就是能够随机的取不同值的变量. 随机变量可以使 **离散的(discrete)** 或者是 **连续的(continuous)**, 离散随机变量有有限或可数的无限个状态(states, 不一定是数值), 而连续随机变量与实数值相关.\n",
    "\n",
    "> 随机变量和可能的取值都用小写无格式字母表示\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $§$ 1.2.3 概率分布(Probability Distributions)\n",
    "\n",
    "**概率分布** 描述变量的值怎么样从它们的各种状态中选取(具体的方法取决于是离散随机变量还是连续随机变量).\n",
    "\n",
    "离散随机变量的概率分布(probability distribution)被称为 **概率质量函数(probability mass function, *abbr.*, PML, 有些国内教材翻译为概率分布律)**, 一般用大写字母 $P$ 表示, 一般用变量的标识来区分不同的概率质量函数而不是通过函数名称来区分, 例如 $P(\\mathtt{x})$ 和 $P(\\mathtt{y})$ 一般来说就表示不同的概率质量函数. 还可以简记作 $\\mathtt{x} ~ P(\\mathtt{x})$ , 对于 x 的某个状态值 $x_1$, 我们可以用 $P(x_1)$ 或 $P(\\mathtt{x} = x_1)$ 表示这个状态的概率值. 对于有多个随机变量的概率分布 , 叫做 **联合概率分布(joint probability distribution)**, 例如 $P(\\mathtt{x} = x, \\mathtt{y} = y)$ 或 $P(\\mathtt{x}, \\mathtt{y})$ (或记作 $P(x \\cap y)$ 或 $P(xy)$).\n",
    "\n",
    "关于 x 的PMF $P(\\mathtt{x})$ 必须满足以下几个条件:\n",
    "\n",
    "* $P$ 的定义域必须包含 x 的所有可能的状态\n",
    "* $\\forall x_i \\in x,\\ 0 \\le P(x_i) \\le 1$\n",
    "* $\\sum_{x_i \\in x} P(x_i) = 1$ 我们把这一条性质称为 **归一化(nornalized)** 的\n",
    "\n",
    "连续随机变量的概率分布被称为 **概率密度函数(probability density function, *abbr.*, PDF)**, 如果函数是 $p$ 关于 x 的PDF, 则必须满足以下三个条件:\n",
    "\n",
    "* $p$ 的定义域是 x 所有状态的集合.\n",
    "* $\\forall x \\in \\mathtt{x}, p(x) \\ge 0$, 注意这里不要求 $p(x) \\le 0$\n",
    "* $\\int{p(x)}\\mathrm{d}x = 1$\n",
    "\n",
    "PDF 没有直接给定某个状态的概率, 而是给出了落在面积为 $\\sigma x$ 的无限小(infinitesimal)区域的概率是 $p(x) \\sigma x$. 我们可以通过对 PDF 求积分(integrate)来获得点集的概率质量. 对于单变量(univariate) PDF , x 在区间 $[a, b]$ 的概率为 $\\int_{[a, b]} p(x) \\mathrm{d} x$.\n",
    "\n",
    "例如概率在实数区间 $[a, b]$ ( $a < b$ ) 上均匀分布(uniform distribution), 考虑函数 $u(x; a, b)$ , `;` 表示以什么作为参数(parametrized by),  $x$ 是函数的自变量(argument), 而 $a$ 和 $b$ 是函数的参数(parameters), 并且对于所有 $x \\notin [a, b], u(x; a, b) = 0$, 而对于所有 $x \\in [a, b], u(x; a, b) = \\frac{1}{b - a}$, 可记作 $x ~ U(a, b)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $§$ 1.2.4 边缘概率(Marginal Probability)\n",
    "\n",
    "有时候我们想求的一组变量中的一个子集的(联合)概率分布, 例如对于离散型概率分布 $P(x, y)$, 我们应用求和法则(sum rule) $\\forall x_i \\in x, P(x = x_i) = \\sum_{y_j} P(x = x_i, y = y_j)$, 而对于连续型概率分布 $p(x) = \\int p(x, y) \\mathrm{d} y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $§$ 1.2.5 条件概率(Conditional Probability)\n",
    "\n",
    "条件概率是某个时间在给定其他事件发生时出现的概率:\n",
    "\n",
    "$$P(y = y_i | x = x_j) = \\frac{P(y = y_i, x = x_j)} {P(x = x_j)}$$\n",
    "\n",
    "> 注意区分条件概率和在从事某个动作之后会发生什么(这被称为 **干预查询(intervention query, 属于因果模型(cause modeling)的范畴, 本书不介绍)** )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $§$ 1.2.6 条件概率的链式法则(chain rule, *aka.*, 乘性法则(product rule))\n",
    "\n",
    "任何多随机变量联合概率分布都可以变成只有一个随机变量的条件概率分布:\n",
    "\n",
    "$$P(x^{(1)}, \\cdots, x^{n}) = P(x^{(1)}) \\prod_{i = 2}^n P(x^{(i)} | x^{(1)}, \\cdots, x^{(i - 1)})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $§$ 1.2.7 独立性(independence) 和条件独立性(conditional independence)\n",
    "\n",
    "如果 $\\forall x \\in \\mathtt{x}, y \\in \\mathtt{y}, p(\\mathtt{x} = x, \\mathtt{y} = y) = p(\\mathtt{x} = x) \\times p(\\mathtt {y} = y)$, 则称随机变量 x 和随机变量 y 是 **相互独立的(independent)**, **简记作 x $\\perp$ y** .\n",
    "\n",
    "如果 $\\forall x \\in \\mathtt{x}, y \\in \\mathtt{y}, z \\in \\mathtt{z}, p(\\mathtt{x} = x, \\mathtt{y} = y | \\mathtt{z} = z) = p(\\mathtt{x} = x | \\mathtt{z} = z) \\times p(\\mathtt{y} = y | \\mathtt{z} = z)$, 则称 x 和 y 是 **条件独立的** , **简记作 x $\\perp$ y | z** .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $§$ 1.2.8 期望(Expectation), 方差(Variance) 和 协方差(Covariance)\n",
    "\n",
    "函数 $f(x)$ 对于概率分布 $P(x)$ 的 **期望(expectation)** 或 **期望值(expected value)** 是指, 当 x 由 *P* 产生, *f* 作用于 *x* 时, $f(x)$ 的平均值. \n",
    "\n",
    "对于离散型随机变量:\n",
    "\n",
    "$$\\mathbb{E}_{x \\sim P} [f(x)] = \\sum_x P(x) f(x)$$\n",
    "\n",
    "\n",
    "对于连续型随机变量:\n",
    "\n",
    "$$\\mathbb{E}_{x \\sim p} [f(x)] = \\int_x p(x) f(x)$$\n",
    "\n",
    " \n",
    "> 我们可以将   $\\mathbb{E}_{x \\text{~} P}$ 简写为 $\\mathbb{E}_x[f(x)]$ 或 $\\mathbb{E}[f(x)]$, 并且我们默认方括号是对 **所有随机变量** 的平均, 无歧义的时候可以省略方括号.\n",
    "\n",
    "期望是线性的: $\\mathbb{E}_x [ \\alpha f(x) + \\beta g(x)] = \\alpha \\mathbb{E}_x[f(x)] + \\beta \\mathbb{E}_x [f(x)]$.\n",
    "\n",
    "数学期望的一些简单性质:\n",
    "\n",
    "$$\n",
    "\\mathbb{E} (c) = c \\text{, where } c \\text{ is a constant.}\n",
    "$$\n",
    "$$\\mathbb{E} \\left[ \\sum_{i=1}^m c_i u_i(X) \\right] = \\sum_{i=1}^m c_i \\mathbb{E} [u_i(X)] \\text{, where } u_i \\text{ is a function about a random variable } X$$\n",
    "\n",
    "> [Reference: PSU online courses](https://onlinecourses.science.psu.edu/stat414/node/63)\n",
    "\n",
    "**方差(variance)** 衡量关于 x 的函数的值和我们对于 x 按照它的概率分布进行采样之间有多大的差距:\n",
    "\n",
    "$$\\mathtt{Var} (f(x)) = \\mathbb{E} [(f(x) - \\mathbb{E}(f(x)))^2]$$\n",
    "\n",
    "\n",
    "经过简单的变换(记得把内层嵌套的数学期望当做常数转移到外层数学期望外面), 反差还可以表示为\n",
    "\n",
    "$$\n",
    "\\mathtt{Var} (f(x)) = \\mathbb{E} [ f(x)^2 ] - \\mathbb{E}^2 [ f(x) ]\n",
    "$$\n",
    "\n",
    "方差的平方根就是 **标准差(standard deviation)** .\n",
    "\n",
    "**协方差(covariance)** 从某种意义上给出了两个变量线性相关性的强度和这些变量的尺度(scale):\n",
    "\n",
    "$$\\mathtt{Cov}(f(x), g(y)) = \\mathbb{E}[(f(x) - \\mathbb{E}[f(x)]) (g(y) - \\mathbb{E}[g(y)])]$$\n",
    "\n",
    "协方差的绝对值很大意味着变量值变化很大并且和距离他们各自的均值(期望值)很远. 如果协方差为正, 那么这两个变量同时都倾向于取到相对较大的值. 如果协方差为负, 那么其中有一个变量倾向于取得一个相对较大的值而另外一个变量倾向于取得一个相对较小的值. 其他的衡量方法例如 **相关性(correlation)** 将每一个变量的贡献归一化(normize) , 为了只衡量变量的相关性而不受各个变量尺度大小的影响.\n",
    "\n",
    "如果两个变量的协方差不为 0 那么两个变量肯定是相关的, 如果两个变量的协方差为 0 , 则它们一定没有线性关系, 但是它们仍然可能有相关性. 例如从区间 $[-1, 1]$ 上的均匀分布中采样出一个实数 x , 然后对随机变量 s 进行采样, s以 0.5 的概率为 1, 否则为 -1 , 我们可以令 y = sx 来生成一个随机变量, 显然 y 和 x 相关, 但是 Cov(x, y) = 0 .\n",
    "\n",
    "随机向量 $x \\in \\mathbb{R}^n$ 的 **协方差矩阵(covariance matrix)** 是一个 $n \\times n$ 矩阵, 并且 $\\mathtt{Cov} (\\mathtt{x})_{i, j} = \\mathtt{Cov}(x_{i}, x_{j})$, 协方差矩阵的对角线元素就是方差: $\\mathtt{Cov}(x_i, x_i) = \\mathtt{Var}(x_i)$ .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $§$ 1.2.9 常见概率分布\n",
    "\n",
    "**Bernoulli 分布**\n",
    "\n",
    "Bernoulli 分布是单个二值随机变量(binary random variable, 也就是只有两个状态的随机变量, 在这里, 就是 0 和 1 )的分布, 由一个参数 $\\phi \\in [0, 1]$ 控制, 并且 $\\phi$ 表示随机变量值为 1 的概率.\n",
    "\n",
    "$$ P(\\mathtt{x} = 1) = \\phi$$\n",
    "$$P(\\mathtt{x} = 0) = 1 - \\phi$$\n",
    "$$P(\\mathtt{x} = x) = \\phi^x (1 - \\phi)^{1- x}$$\n",
    "$$\\mathbb{E}_\\mathtt{x}(\\mathtt{x}) = \\phi$$\n",
    "$$\\mathtt{Var}_\\mathtt{x} (\\mathtt{x}) = \\phi (1 - \\phi)$$\n",
    "\n",
    "**Multinoulli 分布**\n",
    "\n",
    "> Multinoulli 分布是 **多项式分布(multinormial distribution)** 的一个特殊情况, 很多书上直接使用 **多项式分布** 来指代 **Multinoulli 分布** .\n",
    "\n",
    "又称 **范畴分布(categorical distribution)**, 是 有 k (有限的) 个不同状态的单值离散变量(single discrete variable)的分布.  由参数 向量 $\\boldsymbol{p} \\in [0, 1]^{k - 1}$ 控制, $p_i$ 表示第 i 个状态的概率, 而最后一个(也就是 第 k 个)状态的概率是 $1 - \\boldsymbol{1}^\\top \\boldsymbol{p}$, 并且限制 $\\boldsymbol{1}^\\top \\boldsymbol{p} \\le 1$ .\n",
    "\n",
    "> Multiboulli 分布经常用来表示对象分类的分布, 所以我们一般不会假定第一个状态的数值为 1 之类的(也就是状态不一定有数值), 所以我们也就一般不会去求它们的期望或者方差.\n",
    "\n",
    "Bernoulli 分布和 Mulinoulli 分布都足以用来描述他们领域内的任意分布, 这是因为它们是对那些能够很容易的枚举(enumerate)所有状态的离散型随机变量, 如果是处理连续型随机变量, 因为它们的状态都是不可数的(无限的), 所以像这种只有很少数量的参数的分布函数在处理连续型随机变量的时候必须对随机变量的分布加以严格的限制.\n",
    "\n",
    "**高斯分布(Gaussian distribution)**\n",
    "\n",
    "实数上最常用的分布就是 **正态分布(normal distribution)**, 或称 **高斯分布(Gaussian distribution)** .\n",
    "\n",
    "$$\\mathcal{N} (x; \\mu, \\sigma^2) = \\sqrt{\\frac{1}{2 \\pi \\sigma^2}} \\exp{\\left( - \\frac{1} {2 \\sigma^2} (x - \\mu)^2 \\right)}$$\n",
    "\n",
    "> 参数 $\\mu \\in \\mathbb{R}$ 控制中间峰值的坐标, 并且是分布的均值 $\\mathbb{E}[\\mathtt{x}] = \\mu$, $\\sigma \\in (0, \\infty)$, 标准差为 $\\sigma$, 方差为 $\\sigma^2$ .\n",
    "\n",
    "因为我们对正态分布函数求值的时候, 需要对 $\\sigma$ 平方然后求倒数, 所以我们可以简化为用 $\\beta^{-1}$ 代替 $\\sigma^2$, $\\beta$ 控制精度(precision)或者说分布的方差的倒数:\n",
    "\n",
    "$$\\mathcal{N}(x; \\mu, \\beta^{-1}) = \\sqrt{\\frac{\\beta}{2\\pi}} \\exp \\left( -\\frac{1} {2} \\beta (x - \\mu)^2 \\right)$$\n",
    "\n",
    "正态分布可以推广到 $\\mathbb{R}^n$ 空间, 被称为 **多维正态分布(multivariate normal distribution)** :\n",
    "\n",
    "$$\\mathcal{N} (\\boldsymbol{x}; \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}) = \\sqrt{\\frac{1}{(2 \\pi)^n \\det (\\boldsymbol\\Sigma)}} \\exp \\left( - \\frac{1} {2} (\\boldsymbol{x} - \\boldsymbol{\\mu})^\\top \\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{x} - \\boldsymbol{\\mu}) \\right)$$\n",
    "\n",
    "> 参数是 $\\boldsymbol{\\Sigma}$ 一个 **正定对称矩阵(positive definite symmetric matrix)**, 是分布的协方差矩阵; 参数 $\\boldsymbol{\\mu}$ 依然是分布的均值, 不过现在是一个向量.\n",
    "\n",
    "同样的, 对于单一变量情况, 我们可以使用 **精度矩阵(precision matrix) $\\boldsymbol{\\beta}$** 代替 $\\boldsymbol{\\Sigma}$:\n",
    "\n",
    "$$\\mathcal{N} (\\boldsymbol{x}; \\boldsymbol{\\mu}, \\boldsymbol{\\beta}^{-1}) = \\sqrt{\\frac{\\det \\boldsymbol{\\beta} } {(2 \\pi)^n}} \\exp \\left( - \\frac{1} {2} (\\boldsymbol{x} - \\boldsymbol{\\mu})^\\top \\boldsymbol{\\beta} (\\boldsymbol{x} - \\boldsymbol{\\mu}) \\right)$$\n",
    "\n",
    "我们经常把协方差矩阵固定为一个对角矩阵(diagonal matrix). 一个更简单的版本就是 **各向同性(isotropic)高斯分布**, 它的协方差是一个标量(scalar)乘以一个单位阵(identity matrix).\n",
    "\n",
    "**指数(Exponential)分布和 Laplace 分布**\n",
    "\n",
    "在深度学习中, 我们经常需要一个在 $x = 0$ 出取得边界点(sharp point)的分布 -- 指数分布: $p(x; \\lambda) = \\lambda \\boldsymbol{1}_{x \\ge 0} \\exp (-\\lambda x)$\n",
    "\n",
    "指数分布使用函数 $\\boldsymbol{1}_{x \\ge 0}$ 来指示所有 $x < 0$ 的情况的概率为 0. \n",
    "\n",
    "一个相关的能够允许我们自定义概率质量的边界点在任意位置的分布为 **Laplace distribution**: $\\mathtt{Laplace}(x; \\mu, \\gamma) = \\frac{1} {2 \\gamma} \\exp (-\\frac{|x-\\mu|}{\\gamma})$\n",
    "\n",
    "**Dirac 分布和经验(Empirical)分布**\n",
    "\n",
    "有时候我们想把所有概率分布中的质量向某一个点靠拢, 我们可以使用 **Dirac delta 函数**: $p(x) = \\delta (x - \\mu)$ , 其中 $\\delta$ 函数当参数不为0时值都为 0, 但是它的积分是 1, $\\delta$ 函数不像普通函数一样,每一个 $x$ 都有一个对应的数组值输出, 它是一个 **广义函数(generalized function, 按照积分性质定义的对象)**, 我们可以将 Dirac delta 函数理解为一系列在 $\\mu$ 之外的值越来越小的函数的极限点.\n",
    "\n",
    "所以 Dirc 分布就是一个在 $\\mu$ 处有无限窄又无限高的峰值的分布函数.\n",
    "\n",
    "Dirac 分布经常作为 **经验分布(empirical distribution)** 的一个组成部分: $\\hat{p}(\\boldsymbol{x}) = \\frac {1} {m} \\sum_{i=1}^{m} \\delta (\\boldsymbol{x} - \\boldsymbol{x}^{(i)})$ 将概率质量 $\\frac{1} {m}$ 放在 m 个点 $\\boldsymbol{x}^{(1)}, \\cdots, \\boldsymbol{x}^{(m)}$ 上. \n",
    "\n",
    "> Dirac delta 函数只是在经验分布作用在连续型随机变量的时候需要用到, 对于离散型随机变量, 经验分布可以被定义成一个 Multinoulli 分布, 并且每个输出值的概率就是该值在训练集合(training set)中的 **经验频率(empirical frequency)** .\n",
    "\n",
    "当我们在训练集上训练模型时, 我们可以认为从这个训练集上得到的经验分布指明了我们采样来源的分布, 还有就是它是训练数据的似然最大的那个概率密度函数.\n",
    "\n",
    "**混合分布(Mixtures of Distribution)**\n",
    "\n",
    "混合分布由一些组件(component)分布构成, 每次试验, 样本是由哪个组件产生的取决于从一个 Multinoulli 分布中采样的结果: $P(x) = \\sum_i P(x | c = i)P(c = i)$(**全概率公式,可结合 Venn 图证明**), 其中 $P(c)$ 是对各组件的一个 Multinoulli 分布.\n",
    "\n",
    "前面的实数上的经验分布就是一个混合分布. 混合模型的思想将会在后面的学习中用到, 例如这里的 $c$ 就相当于一个 **潜变量(latent variable, See Chapter 16)** .\n",
    "\n",
    "一个强大且常见的就是 **高斯混合模型**, 它的组件 $p(\\mathtt{x} | c = i)$ 是高斯分布, 每一个组件都有他们单独的均值参数 $\\boldsymbol{\\mu}^{(i)}$ 和单独的协方差参数 $\\boldsymbol{\\Sigma}^{(i)}$, 为了方便, 可以添加约束, 组件之间可以共享同一个协方差 $\\boldsymbol{\\Sigma}^{(i)} =  \\boldsymbol{\\Sigma} \\forall i$, 而且跟单独的高斯分布一样, 可以限制每一个组件的协方差矩阵是对角的(diagonal)或者是各向同性的(isotropic). \n",
    "\n",
    "除了协方差和均值之外, 高斯混合每个组件$i$ 的参数还指定了 **先验概率(prior probability)** $\\alpha_i = P(c = i)$ , \"先验(prior)\" 一词表明了在观察到 $\\mathtt{x}$ 之前传递给模型关于 $c$ 的信念(belief), 作为对比 $P(c | \\boldsymbol{x})$ 是 **后验概率(posterior probability)** 因为它是在观察到 $\\mathtt{x}$ 之后才计算. 高斯混合模型是概率密度的 **万能近似器(universal approximator)**, 任何平滑的概率密度都可以用具有足够多组件的高斯混合模型以任意精度去逼近(还是有非零的误差).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $§$ 1.2.10 常用函数的一些有用性质(property)\n",
    "\n",
    "**logistic sigmod 函数**\n",
    "\n",
    "$$\\sigma (x) = \\frac{1} {1 + \\exp (-x)}$$\n",
    "\n",
    "logistic sigmod 函数经常用来生成 Bernoulli 分布中的参数 $\\phi$, 因为它的值域是 $(0, 1)$ .\n",
    "\n",
    "![Figure 3.3][9]\n",
    "\n",
    "> 当自变量的绝对值特别大的时候, 函数值趋于 **饱和(saturate)**, 也就是对输入值的变化变得不敏感.\n",
    "\n",
    "**softplus 函数**\n",
    "\n",
    "$$\\zeta (x) = \\log(1 + \\exp (x))$$\n",
    "\n",
    "\n",
    "softplus 函数经常用来生成正态分布的 $\\beta$ 或 $\\sigma$, 因为它的值域是 $(0, \\infty)$.  softplus 名字的由来是它差不多就是一个 **softened** 版本的 $x^+ = \\max (0, x)$ (**正部函数(positive part function))** .\n",
    "\n",
    "![Figure 3.4][10]\n",
    "\n",
    "以下为一些有用的最好记住的函数性质:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\sigma (x) = \\frac{\\exp (x)} {\\exp (x) + \\exp (0)}\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac {\\mathrm{d}} {\\mathrm{d}x} \\sigma (x) = \\sigma(x) (1 - \\sigma(x))\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "1 - \\sigma(x) = \\sigma(-x)\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\log \\sigma(x) = - \\zeta(-x)\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{\\mathrm{d}}{\\mathrm{d}x} \\zeta(x) = \\sigma(x)\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\forall x \\in (0,1), \\sigma^{-1}(x) = \\log (\\frac{x}{1-x})\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\forall x > 0, \\zeta^{-1}(x) = \\log (\\exp (x) - 1)\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\zeta(x) = \\int_{-\\infty}^{x} \\sigma(y)\\mathrm(d)y\n",
    "\\end{equation}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\zeta(x) - \\zeta(-x) = x\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "> 函数 $\\sigma^{-1}(x)$ 在统计学中被称为 **分对数(logit)**, 但是在机器学习中很少用到.\n",
    "\n",
    "> 最后一条性质为函数名提供了正当理由, 因为就像正部函数($x^+$) 和 负部函数 $x^-$ 之间的关系 $x^+ - x^- = x$\n",
    "\n",
    "  [9]: ./images/1517034158757.jpg\n",
    "  [10]: ./images/1517036009925.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $§$ 1.2.11 贝叶斯规则(Bayes' Rule)\n",
    "\n",
    "$$P(x | y) = \\frac{P(x, y)}{P(y)} = \\frac{P(x)P(y | x)}{P(y)}$$\n",
    "\n",
    "> 可以用  $P(y) = \\sum_{x_i} P(y | x_i) P(x_i)$(**全概率公式**) 来求的 $P(y)$, 所以我们并不需要事先知道 $P(y)$ 的信息.\n",
    "\n",
    "> 贝叶斯规则可以由条件概率的定义直接推导出来\n",
    "\n",
    "> 这里的 $P(x)$ 就叫做 **先验概率(prior probability)**, 而 $P(x | y)$ 相当于加上了观测 $y$ 的 **后验概率(posterior probability)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $§$ 1.2.12 连续型变量的技术细节\n",
    "\n",
    "> 对连续型变量及其 PDF 需要用数学的一个分支 -- **测度论(measure theory)** 来扩展概率论. 测度论超出了本书的范围, 不过这里可以简要的说明一下测度论要解决的问题.\n",
    "\n",
    "我们知道连续型向量值(随机变量) $\\mathtt{x}$ 落在某个集合 $\\mathbb{S}$ 中的概率是 $p(x)$ 对集合 $\\mathbb{S}$ 积分(integral) 得到的. 但是某些 $\\mathbb{S}$ 的选择可能会引起悖论(paradox). 例如, 构造两个集合 $\\mathbb{S}_1$ 和 $\\mathbb{S}_2$ 使得 $p(x \\in \\mathbb{S}_1) + p(x \\in \\mathbb{S}_2) > 1 \\text{ , and } \\mathbb{S}_1 \\cap \\mathbb{S}_2 = \\emptyset$ 是有可能的. 这样的集合通常是使用了大量的实数的无限精度(infinite precision)来构造的, 例如构造 **分形集合(fractal-shaped sets)** 或通过由由理数(rational numbers)构成的集合的变换(transform)来定义的集合(Banach-Tarski 定理(theorem)给出了这类集合的一个有趣的例子). 测度论的一个重要贡献就是提供了一些集合的特征使得我们在计算概率的时候不会遇到悖论. 在本书中, 我们只会对一些简单的集合进行积分, 所以测度论相关知识不会被考虑.\n",
    "\n",
    "测度论对描述那些在 $\\mathbb{R}^n$ 上大部分点适用而在少数几个边界情况(corner case)下不适用的定理很有用. 测度论为描述那些微小(negligibly small)的点集(set of points)提供了严格(rigorous)的方式, 这样的集合被称为 **零测度(measure zero)**. 我们可以认为零测度集在我们的度量空间中不占用空间, 例如在 $\\mathbb{R}^2$ 空间中, 一条线有零测度, 被填充的多边形就是有正测度(positive measure). 有限个数的零测度集的并仍然是零测度的(所以所有的有理数构成的集合测度为零).\n",
    "\n",
    "另一个在测度论中的术语是 **几乎处处(almost everywhere)**, 一个几乎处处成立的性质(property)在除了一个零测度集之外的空间上成立, 因为这些例外占有微小(negligibly amount)的空间, 所以它们在很多应用上都可以被忽略. 许多在所有离散值上成立的概率论结果对于连续型值来说几乎处处成立.\n",
    "\n",
    "连续型变量的另外一个技术细节涉及到处理那些互相之间有确定(deterministic)函数关系的连续型随机变量. 假定有两个连续型随机变量 $\\mathtt{x}$ 和 $\\mathtt{y}$, 并且有 $y = g(x)$, $g$ 是一个可逆的, 连续可微(continous, differentiable)的函数(transformation). 但是 $p_y(y) = p_x(g^{-1}(y))$ 是错误的. 例如, 标量随机变量 x 和 y, 并且有 $y = \\frac{x} {2}, x \\sim U(0,1) $ . 假设 $p_y(y) = p_x(2y)$, 也就是 $p_y(y)$ 在除了 $[0, \\frac{1}{2}]$ 之外都是 0, 也就是 $\\int p_y(y) \\mathrm{d}y = \\frac{1} {2}$, 这跟概率分布的定义相矛盾. 这是因为没有考虑由 $g$ 造成的空间变形(distortion), 回忆落在一个无穷小面积 $\\delta x$ 上的概率为 $p(x) \\delta x$, 如果 $g$ 能扩展(expand)或收缩(contract)空间, 在 $x$ 空间内的包围这 $x$ 的无穷小体积(volume)在 $y$ 空间中可能会有不同的体积. 为了纠正这一问题, 我们需要保持性质 $|p_y(g(x))\\mathrm{d}y| = |p_x(x)\\mathrm{d}x|$, 所以有:\n",
    "\n",
    "$$p_y(y) = p_x(g^{-1}(y)) \\left |\\frac{\\partial x} {\\partial y} \\right|$$\n",
    "$$p_x(x) = p_y(g(x)) \\left| \\frac {\\partial g(x)} {\\partial x} \\right|$$\n",
    "\n",
    "\n",
    "对于更高维度, 微分运算(derivative)扩展为 **Jacobian 矩阵($J_{i,j} = \\frac {\\partial x_i} {\\partial y_i}$,相当于 $x \\rightarrow y$ 的坐标转换)** 的行列数(determinant), 所以对于实数值向量 $x$ 和 $y$,  有\n",
    "\n",
    "$$p_x(x) = p_y(g(x)) \\left| \\det \\left( \\frac{\\partial g(x)}{\\partial x} \\right) \\right|$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $§$ 1.2.13 信息论 (Information Theory)\n",
    "\n",
    "> 推荐阅读: Cover and Thomas(2006) 或 MacKay(2003)\n",
    "\n",
    "信息论是应用数学(Applied Math)的一个分支, 主要是用来量化(quantify) **信号(signal)** 中包含的信息. 信息论最开始是用于在包含造成噪声(noisy)的信道(channel)中发送信息, 例如信息论告诉我们如何设计最优编码(optimal code), 计算从使用多种编码方案的特定概率分布取样的消息的期望长度. 在机器学习中, 我们可以把信息论应用在连续型变量上. 在本书中, 我们只涉及到少数几个信息论的概念, 用于描述(characterize)概率分布和量化概率分布之间的相似度(similiarity). \n",
    "\n",
    "信息论的基本想法是一个不太可能发生的事件的发生能够比一个很有可能发生的事件的发生要提供更多的信息. 例如说消息\"今天早上太阳升起\"消息少得没必要发送, 而\"今天早上有日食\"信息量就很丰富.\n",
    "\n",
    "* 很可能发生的事件的信息量(information content)比较少, 在极端情况下, 必须发生的事件没有任何信息量.\n",
    "* 较不可能发生的事件有更多的信息量. \n",
    "* 独立事件具有增量(additive)的信息, 例如抛硬币两次正面朝上的信息量应该是一次正面朝上的信息量的两倍.\n",
    "\n",
    "为了满足上述三个性质, 我们定义一个事件 $\\mathtt{x} = x$ 的 **自信息(self-information)** 为 $I(x) = - \\log P(x)$ .\n",
    "\n",
    "因为 $I(x)$ 使用的是自然对数, 所以定义 $I(x)$ 的单位是 **奈特(nats)**, 一奈特是以 $\\frac{1} {e}$ 的概率观察到某事件的信息量. 其他使用以 2 为底的对数的单位是 **比特(bit)** 或 **香农(shannous)** , 通过比特度量的信息只是通过奈特度量的信息的常数倍(rescaling). \n",
    "\n",
    "当 x 是连续的, 我们使用类似的差不多的定义, 不过一些源自离散形式的性质就丢失了. 例如单元密度(unit density)的事件信息量依然为 0, 但是不能保证它一定发生.\n",
    "\n",
    "自信息只处理单个的输出, 我们可以用 **香农墒(shannon entropy)** 来量化整个概率分布的总的不确定性:\n",
    "\n",
    "$$H(x) = \\mathbb{E}_{x \\sim P} [I(x)] = -\\mathbb{E}_{x \\sim P} [\\log P(x)]$$\n",
    "\n",
    "> 也可记作 $H(P)$\n",
    "\n",
    "一个分布的香农墒就是遵循该分布的事件的期望信息总量. 它给出了编码一个分布上的符号(symbol)所需要的平均单元数(units, 例如基于以 2 为底的对数时就是比特数)的下界(lower bound). 接近确定性的分布具有较低的墒, 接近均匀分布的概率分布具有较高的墒. 当 x 是连续的, 香农墒被称为 **微分墒(differential entropy)** . 下图给出了二值随机变量分布的香农墒. \n",
    "\n",
    "\n",
    "![Figure 3.5][11]\n",
    "\n",
    "对于同一随机变量的两个相互独立的概率分布 $P(x)$ 和 $Q(x)$, 我们可以使用 **KL散度(Kullback-Leibler divergence)**:\n",
    "\n",
    "$$D_{KL}(P \\Vert Q) = \\mathbb{E}_{x \\sim P} \\left[ \\log \\frac{P(x)}{Q(x)} \\right] = \\mathbb{E}_{x \\sim P}[\\log P(x) - \\log Q(x)]$$\n",
    "\n",
    "在离散型随机变量的情况下, KL 散度衡量的是, 当我们使用一种被设计成能够使得概率分布$Q$ 产生的消息的长度最小的编码, 发送包含由概率分布 $P$ 产生的符号的消息时, 所需要的额外信息量(如果是使用以2为底的对数, 信息量就用比特衡量).\n",
    "\n",
    "KL 散度最重要的特征是它是非负的(nonnegative). KL 散度为 0 当且仅当离散型随机变量的 $P$ 和 $Q$ 是一模一样的分布或者连续型随机变量的 $P$ 和 $Q$ 的分布\"几乎处处\"相等. KL 散度将度量两个分布之间的距离概念化, 但是又不是真的距离因为 KL 散度不是对称的(symmetric): $D_{KL}(P \\Vert Q) \\ne D_{KL}(Q \\Vert P)$. 这种非对称性(asymmetric)意味着选择  $D_{KL}(P \\Vert Q)$ 还是 $D_{KL}(Q \\Vert P)$ 会产生不一样的结果. \n",
    "\n",
    "![Figure 3.6][12]\n",
    "\n",
    "> 为了说明这两种选择的效果, 我们令 $p$ 为 两个高斯分布的混合, 令 $q$ 为单个高斯分布. 左边的是近似分布 q 在真实分布 p 反之高概率的所有地方都放置高概率, 右边的是近似分布 q 在 真实分布 p 放置低概率的所有地方放置低概率.\n",
    "\n",
    "一个跟 KL 散度密切相关的是 **交叉墒(cross-entropy)**, $H(P, Q) = H(P) + D_{KL}(P \\Vert Q) = - \\mathbb{E}_{x \\sim P}\\log Q(x)$ . 针对 $Q$ 的最小化交叉墒等价与最小化 KL 散度, 因为 $Q$ 并不参与被省略的那一项.\n",
    "\n",
    "> 当我们处理这些量的时候, 经常会遇到 $0 \\log 0$, 按照惯例, $\\lim _{x \\to 0} x \\log x = 0$\n",
    "\n",
    "  [11]: ./images/1517112955868.jpg\n",
    "  [12]: ./images/1517134589413.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $§$ 1.2.14 结构化概率模型(Structured Probabilistic Models)\n",
    "\n",
    "机器学习算法通常设计到大量的随机变量的联和概率分布, 但是这些随机变量中只有少量变量之间直接互相作用, 使用单个函数描述整个联合概率分布往往在计算和统计上面都很低效.  我们可以把概率分布分解成多个因子(factorization)相乘, 例如有三个随机变量 a, b, c, 并且 a 影响 b, b 影响 c , 但是 a 和 c 相互独立, 所以 $p(a, b, c) = p(a) p(b | a) p(c | b)$ . 这样能极大得降低表示联合分布的成本. \n",
    "\n",
    "当我们用图论中的图的概念来表示这种概率分布的分解, 我们把它称为 **结构化概率模型(structured probability model)** 或 **图模型(graphical mpdel)** . 有两种主要的结构化概率模型:  **有向(directed)** 和 **无向的(undirected)** . 这两种图模型都用以顶点表示随机变量, 边表示概率分布能够表示成这两个随机变量之间的直接作用的图 $\\mathcal{G}$ .\n",
    "\n",
    "**有向模型** 中对于分布中的每一个随机变量 $x_i$ 都有一个影响因子(factor), 这个组成 $x_i$ 条件概率分布的影响因子被称为 $x_i$的父结点, 记作 $Pa_{\\mathcal{G}}(x_i)$ : $p(\\mathtt{x} = \\prod_{i} p(x_i | Pa_{\\mathcal{G}}(x_i)))$.\n",
    "\n",
    "![Figure 3.7][13]\n",
    " \n",
    "**无向模型** 中, $\\mathcal{G}$ 中任意结点都相互连接的集合称为 **团(clique, 也就是图论里面的连通分量) $\\mathcal{C}$**, 无向模型中的每个团 $\\mathcal{C}^{(i)}$ 都有一个与之相关联的因子(factor) $\\phi^{(i)}(\\mathcal{C}^{(i)})$, 这些因子仅仅是函数, 不是概率分布, 每个影响因子的输出(output, 也就是值)必须是非负的, 但是没有限制说这些因子的和或者积分(integrate)是 $1$.  随机变量的联合概率和所有这些因子的乘积 **成比例(proportional)**, 也就是说因子的值越大, 可能性也就越大. 因为不保证因子的和或者积分为 1, 所以我们需要一个额外的归一化常数(normalized constant) $\\mathcal{Z}$ 是 $\\phi$ 函数乘积的所有状态的求和或积分. 所以 $p(\\mathtt{x}) = \\frac{1} {\\mathcal{Z}} \\prod_{i} \\phi^{(i)} \\left( \\mathcal{C}^{(i)} \\right)$ \n",
    "\n",
    "![Figure 3.8][14]\n",
    "\n",
    "> 有向模型和无向模型只是描述(descript)概率分布的两种不同方式. 任何概率分布都可以用这两种方式描述. \n",
    "\n",
    "> 在研究部分(Part III)之前,  结构化概率模型仅仅是作为一个描述每种机器学习算法选择的直接概率化关系的语言.\n",
    "\n",
    "  [13]: ./images/1517209835378.jpg\n",
    "  [14]: ./images/1517211421206.jpg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
