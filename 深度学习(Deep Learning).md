---
title: 深度学习(Deep Learning) 
tags: 深度学习, AI, DL, ML,笔记
grammar_abbr: true
grammar_table: true
grammar_defList: true
grammar_emoji: true
grammar_footnote: true
grammar_ins: true
grammar_mark: true
grammar_sub: true
grammar_sup: true
grammar_checkbox: true
grammar_mathjax: true
grammar_flow: true
grammar_sequence: true
grammar_plot: true
grammar_code: true
grammar_highlight: true
grammar_html: true
grammar_linkify: true
grammar_typographer: true
grammar_video: true
grammar_audio: true
grammar_attachment: true
grammar_mermaid: true
grammar_classy: true
grammar_cjkEmphasis: true
grammar_cjkRuby: true
grammar_center: true
grammar_align: true
grammar_tableExtra: true
---
# Notations

# Intro

在现在人工智能(Artificial Intelligence, *abbr.* AI)领域主要需要解决的是那些对人类来说很 **直观的(Intuitively)** 但是难以形式化(formally, *i.e.*, mathematic rules)的描述的问题. 本书讨论的一种方案, 可以让计算机通过较为简单的知识来从经验中学习产生更加复杂的 **层次体系(相互关联的层次概念, hierarchy concepts)** , 我们称这种方法为 **深度学习(AI deep learning)** . 

一些早期的人工智能项目希望通过将整个世界通过人为的硬编码(hard-code)成形式化的语言, 但这个想法的困难实现表明, AI 系统需要能够直接用原始数据中提取模式(extract pattern)的能力来获取(acquire)自己的知识而不是人为的硬编码进去, 这个能力被称为 **机器学习(Machine Learning)**. 

**逻辑回归(Logistic  Regression)** 作为一种简单的机器学习算法可以用来判断是否需要剖腹产, 另一种被称为 **朴素贝叶斯(naive Bayes)** 的机器学习算法可以用来区分是否是垃圾邮件. 但是, 这两种简单的机器学习算法很大程度上依赖于给定数据的表示(representation), 例如在预测是否需要剖腹产时, 医生必须告诉系统几条与之密切相关的患者的信息(e.g. 是否存在子宫疤痕), 表示患者的每条信息被称为 **特征(features)** , 逻辑回归学习这些特征如何与各种结果相关联, 而不能直接想医生一样从核磁共振成像得出结果.  

不管实在 CS 领域还是日常生活领域, 对数据表示的依赖是很正常的现象, 例如要画一条直线将对一下数据分为两类, 在笛卡尔坐标系下显然是不可能的, 但是在极坐标系下就是很简单的.

![Figure 1.1][1] 

但是, 对于很多任务来说, 很难知道什么特征需要被提取出来, 例如我们需要判断图片中是否是一辆车, 我们知道车有轮子, 但是轮子可能会有金属部分被太阳反射的光, 车落在轮子上的阴影, 轮子上的挡泥板... 等等, 一个解决方案就是使用机器学习, 不仅把数据的表示映射到输出, 还要使用机器学习发掘出数据的表示本身, 这种方案被称为 **表示学习(representation learning)** . 学习到的表示往往比手动设计的特征集更加好, 而且只需要很少的人工干预.

表示学习的一个典型例子就是 **自编码器(autoencoder)**, 自编码器由一个编码器(encoder, 将输入数据转换成不同的表示, )和一个解码器(decoder, 将新表示转换回原来的格式)组成. 自编码器被训练成通过编码器和解码器能够保留尽可能多的信息, 而且新表示就很多很好的属性(properties), 不同的自编码器实现不同的属性. 

但我们设计用来学习特征(features)的算法或特征时, 我们的目标一般是分离出能够解释被观测数据的 **变化因素(factors of variation)**, 这些因素通常是不能直接观察到的量, 他们可以被看作是数据的概念或抽象(abstract). 在分析图像中的车时, 因素可能是车的颜色, 位置, 太阳的方位角等等. 大部分应用需要理清(disentangle)变化因素, 丢弃我们不关心的变化因素. 显然, 从原始数据中提取出如此高级别, 抽象的特征是困难的, 很多类似于人的口音之类的变化因素, 只能使用复杂的接近人类的理解来辨识, 这几乎跟解决原问题一样复杂, 至少乍一看, 表示学习对我们没帮助.

**深度学习** 通过使用更加简单的表示来表达复杂表示, 解决了表示学习中最核心的问题. 例如对一个人物图像的识别可以通过组合类似于转角, 轮廓(他们转而由边线定义)的简单概念.

![Figure 1.2][2]

上图中, 输出像素在可见层, 然后是一系列从图像中提取的越来越多抽象特征的 **隐藏层(hidden layers, 因为他们的值不是输入直接给出的)**, 模型必须判断那些概念(concepts) 对于解释可见数据之间的关系是有用的.

深度学习的一个典型模型就是 **前馈神经网络(feedforward netword)** 或称 **多层感知机(MultiLayer Perceptron, *abbr.*, MLP)**. MLP 仅仅是通过一个数学函数将一组输入值映射到输出值, 这个函数又是有很多更加简单的函数复合而成, 我们可以认为每一个不同函数的应用都提供了输入的一个新的表示. 

另外一种对深度学习的理解是深度(depth)允许计算机学习一个多步骤(multi-step)的程序, 每一层表示可以被认为是计算机在并行执行了一系列指令之后的内存状态, 网络越深, 累积执行的指令也就越多, 并且后面的指令可以使用前面的指令的结果, 所以在激活的某层里面并不是所有信息都是编码了解释输入的变化因素. 这些表示还存储了有助于帮助模型更好地组织其处理过程的状态信息, 虽然这些状态信息与具体的输入内容无关.

主要有两种用来度量模型深度的方法. 第一种是基于评估架构(Architecture)必须要执行的顺序指令数目. 我们可以认为是对模型给定输入之后, 描述模型计算出各种输出的流程图(flowchart)中最长路径的流程图的路径(因为流程图的长度取决于我们允许哪些函数能够在流程图中的每一步中被使用), 就像两个完全相同的程序使用不同的语言编写会有不同的长度.  

![Figure 1.3][3]

比如同样的逻辑回归模型, 如果使用加法, 乘法和 logistic sigmoid 符号作为模型元素, 那么这个模型的深度为 3, 如果把逻辑回归视为元素本身, 那么该模型的深度为 1.

另外一种度量模型深度的方法是在深度概率模型中是使用的方法, 将描述概念之间的关系的图的深度作为模型深度而不是计算图的深度. 在这种情况下计算每个概念(concept)的表示(representation)的流程图的深度(也就是第一种方法计算出来的)可能比概念之间关系的图中该概念的深度更加深, 例如一个 AI 系统观察一个有一直眼睛在阴影中的人脸的图的时候, 它最初可能只看到一只眼睛, 但当系统检测出脸部之后, 系统可以推断出第二只眼睛也是可能存在的. 在这种情况下, 概念图只有两层(眼睛和脸部), 而如果计算每一个概念的计算模型都需要 `!$n$` 次, 那么计算图的深度为 `!$2n$`.

因为并不总是清楚是计算图的深度还是概率模型图的深度哪一个更加有意义, 所以架构的深度没有单一的正确值. 相比传统的机器学习, 深度学习研究的模型涉及更多的(计算机)学到的函数或学到的概念的组合.

![Figure 1.4][4]

上图表示了 AI 领域不同 AI 训练方法之间的关系.

![Figure 1.5][5]

上图表示了AI 各个训练方法之间的高层次原理, 阴影的方框表示能够从数据中自主学习的部件, 表示学习中输入到各种特征(features)之间的箭头表示了各种表示(representation)的转换.

本书分为三个部分, 第一部分介绍一些基本的数学方法和机器学期概念, 第二部分介绍最成熟的深度学习算法, 这些技术基本上得到了解决, 第三部分讨论一些广泛的被认为是深度学习未来研究的重点的具有展望性的想法.

![Figure 1.6][6]

上图描述了本书的高层结构, 其中箭头表示先后依赖关系.

## DL 的历史趋势

> 略

# (p) Part 1 Applied Math and Machine Learning Basis

## Linear Algebra 线性代数




  [1]: ./images/1516606697255.jpg
  [2]: ./images/1516613842738.jpg
  [3]: ./images/1516621710096.jpg
  [4]: ./images/1516624370367.jpg
  [5]: ./images/1516624435832.jpg
  [6]: ./images/1516624998426.jpg