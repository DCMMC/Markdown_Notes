{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from cuml.metrics import pairwise_distances\n",
    "from scipy import sparse\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 协同过滤\n",
    "协同过滤(Collaborative Filtering)是一种经典的且被工业界广泛使用推荐算法。\n",
    "狭义的协同过滤定义为：通过收集大量其他**相似**用户的偏好或品味信息（**协同**）来自动地对预测（**过滤**）当前用户的兴趣。\n",
    "广义的协同过滤则定义为：使用多个主体，观点，数据源进行合作来过滤信息或者模式的过程。\n",
    "\n",
    "协同过滤算法分为两类：\n",
    "\n",
    "* 基于用户的协同过滤：构建一个 user-item 矩阵，然后寻找该用户的相似用户在 user-item 矩阵中的信息来预测该用户的偏好结果。\n",
    "* 基于目标项目（item）的协同过滤：构建一个 item-item 矩阵来衡量不同项目之间的关联度，然后使用该矩阵来推导用户的偏好。\n",
    "\n",
    "这里主要是实现一个基于用户的协同过滤算法，基于用户的协同过滤算法的一般定义为（用户 $i$ 对项目 $m$ 的打分）：\n",
    "\n",
    "$$score(i, m) = \\text{agg}_{j \\in N}(score(j, m))$$\n",
    "其中 $N$ 表示 $i$ 的某个邻域（一般以相似度作为度量），$agg$ 用户对该邻域内所有打分结果进行聚合运算（i.e., 加权平均），包括一些预处理（归一化，收缩，等）。\n",
    "\n",
    "本节将要实现的算法的核心公式为（以预测用户 $i$ 对电影 $m$ 的偏好度为例）：\n",
    "\n",
    "$$score(i, m) = \\frac{\\sum_{k \\in N(i, m)} sim(X(i), X(k)) \\times score(k, m)}{\\sum_{k \\in N(i, m)} sim(X(i), X(k))}$$\n",
    "其中 $X(i)$ 代表用户 $i$ 对所有电影的打分（当然要预测的电影的打分是为 0 的）向量，$N(i, m)$ 在本例中简单选用为所有给电影 $m$ 打了分的用户，相似度量采用**余弦距离（cosine distance）**：\n",
    "\n",
    "$$sim(X(i), X(k)) = \\frac{\\langle X(i), X(k) \\rangle}{\\lVert X(i) \\rVert \\lVert X(k) \\rVert}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 6.223333358764648s.\n",
      "Done in 1.8312866687774658s.\n"
     ]
    }
   ],
   "source": [
    "def read_data(filename):\n",
    "    user2id = {}\n",
    "    st = time()\n",
    "    X = np.zeros((10000, 10000))\n",
    "    with open(filename) as f:\n",
    "        for l in f.readlines():\n",
    "            # The users of X_train and X_test are same\n",
    "            # user: unique ineter ids with #user = 10000, but the id not in [0, 10000] and may appear randomly\n",
    "            # movie: unique integer ids in range [1, 10000]\n",
    "            # rate: unique integer rate in range [1, 5]\n",
    "            # 训练集和测试集中的数据并不是规整的按电影来划分的，也就是说对于某个电影，训练集和测试集都有一部分用户打分，\n",
    "            # 不过这些用户不重叠，我们的任务便是用训练集中对该电影的打分以及对应用户的信息来预测测试集中对该电影的打分\n",
    "            # 因为数据规模不是很大，矩阵虽然是 $10000 \\times 10000$ 大小的，不过比较稀疏（训练集稀疏度 6.89%，测试集 1.72%），\n",
    "            # 所以我们采用全量数据（i.e., 10000 维），并且在后面的计算中尽可能使用稀疏矩阵的形式参与计算。\n",
    "            user, movie, rate, _ = l.split()\n",
    "            movie = int(movie) - 1\n",
    "            rate = int(rate)\n",
    "            if user not in user2id:\n",
    "                user2id[user] = len(user2id)\n",
    "            user = user2id[user]\n",
    "            X[user, movie] = rate\n",
    "    print(f'Done in {time() - st}s.')\n",
    "    return X\n",
    "\n",
    "X_train = read_data('netflix_train.txt')\n",
    "X_test = read_data('netflix_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_sp(X, X_hat):\n",
    "    # only nonzero entries in X_test will be used as targets when calculating RMSE\n",
    "    # 因为我们只需要考虑测试集中非零项，所以我们不能直接使用 sklearn 提供的 RMSE。因为这样会导致\n",
    "    # 不需要测试的数据也被纳入误差的度量计算中，并且 $n = 10000^2$ 而不是实际的 $n_\\text{sample} \\approx 1.72M$，\n",
    "    # 这样可能会导致 RMSE 比实际值偏小。\n",
    "    st = time()\n",
    "    test_point = X.astype(np.bool)\n",
    "    loss = np.sqrt(np.power(\n",
    "        X_hat[test_point] - X[test_point], 2).mean())\n",
    "    print(f'rmse_sp took {time() - st:.2f}s.')\n",
    "    return loss\n",
    "\n",
    "def rmse_cuda(X, X_hat):\n",
    "    st = time()\n",
    "    test_point = X.astype(np.bool)\n",
    "    loss = cp.sqrt(cp.power(\n",
    "        X_hat[test_point] - X[test_point], 2).mean()).get().item()\n",
    "    print(f'rmse_sp took {time() - st:.2f}s.')\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_cos_distance(X):\n",
    "    X = X.T / X.sum(axis=1)\n",
    "    return X.T @ X\n",
    "\n",
    "def coll_filter(train, test, contain_zero_rates=False):\n",
    "    X_train_csr = sparse.csr_matrix(train)\n",
    "    X_test_csr = sparse.csr_matrix(test)\n",
    "    st = time()\n",
    "    # 首先计算好 $sim(X(i), X(k))$ 避免重复计算\n",
    "    sim = cosine_similarity(X_train_csr)\n",
    "    # 计算分子部分（对用户打分结果按照相似度进行加权）\n",
    "    score = sim @ X_train_csr\n",
    "    # 计算分母部分（i.e., 归一化因子）\n",
    "    # nonzero => 1, renormalized, i.e., k \\in users who have rated movie j\n",
    "    # 如果不这样做的话，会有很多没有给 movie j 打分（rate=0）的用户消耗掉一部分的权重（概率分布），\n",
    "    # 进而造成预测结果偏小\n",
    "    if contain_zero_rates:\n",
    "        Z = sim @ np.ones((10000, 1))\n",
    "    else:\n",
    "#         X_train_csr[X_train_csr.nonzero()] = 1\n",
    "        X_train_csr = X_train_csr.astype(np.bool)\n",
    "        Z = sim @ X_train_csr\n",
    "    # 因为分母会有一些结果为 0（当所有用户偏好都与该用户差别过大时，或者该用户打分信息很极少时），\n",
    "    # 所以我们需要对 nan 转化为 0\n",
    "    score_pred = np.nan_to_num(score / Z)\n",
    "    print(f'Calculating score_pred done in {time() - st:.2f}s.')\n",
    "    loss = rmse_sp(X_test, score_pred)\n",
    "    return loss\n",
    "\n",
    "def coll_filter_cuda(train, test, contain_zero_rates=False):\n",
    "    cp.cuda.Device(3).use()\n",
    "    X_train_cuda = cp.array(train)\n",
    "    X_test_cuda = cp.array(test)\n",
    "    st = time()\n",
    "    sim = pairwise_cos_distance(X_train_cuda)\n",
    "    score = sim @ X_train_cuda\n",
    "    if contain_zero_rates:\n",
    "        Z = sim @ cp.ones((10000, 1))\n",
    "    else:\n",
    "        Z = sim @ X_train_cuda.astype(np.bool)\n",
    "    score_pred = score / Z\n",
    "    print(f'Calculating score_pred done in {time() - st:.2f}s.')\n",
    "    loss = rmse_cuda(cp.array(test), score_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating score_pred done in 12.54s.\n",
      "rmse_sp took 0.09s.\n",
      "RMSE: 1.02821\n",
      "Calculating score_pred done in 7.98s.\n",
      "rmse_sp took 0.09s.\n",
      "RMSE when k includes all users who're not rate this movie: 2.60669\n"
     ]
    }
   ],
   "source": [
    "rmse = coll_filter_cuda(X_train, X_test)\n",
    "print(f'RMSE: {rmse:.5f}')\n",
    "\n",
    "rmse_ill_Z = coll_filter_cuda(X_train, X_test, contain_zero_rates=True)\n",
    "print(\"RMSE when k includes all users who're not \" +\n",
    "      f\"rate this movie: {rmse_ill_Z:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于梯度下降的矩阵分解算法\n",
    "\n",
    "因为给定特征矩阵是一个稀疏矩阵，基于低秩假设，特征维度为 10000 的矩阵的特征值也很稀疏（或者很小），于是我们可以将矩阵分解为两个特征维度很小的隐空间特征表达：\n",
    "\n",
    "$$X_{m \\times n} \\approx U_{m \\times k} V_{n \\times k}^T$$\n",
    "其中 $k \\ll n$。\n",
    "\n",
    "特别的，我们在电影推荐任务中，使用 X_train 构建出矩阵分解后，使用它们的乘积来预测 X_test 中的那部分结果。\n",
    "\n",
    "这里我们采用梯度下降算法来求解上述分解，目标函数为：\n",
    "\n",
    "$$J = \\frac{1}{2} \\lVert A \\odot (X - UV^T \\rVert_F^2 + \\lambda \\lVert U \\rVert_F^2 + \\lambda \\lVert V \\rVert_F^2)$$\n",
    "其中 $\\odot$ 表示 Hadamard 乘积（逐位乘），$A$ 为指示矩阵，$A_{ij} = 1$ 表示 $X_{ij} 的值已知，$$\\lVert A \\rVert_F^2 = \\sqrt{\\sum_i \\sum_j A_{ij}}$ 表示矩阵 Frobenius 范数，$\\lambda$ 为正则化系数，用于防止过拟合。\n",
    "\n",
    "对目标函数求偏导，得到：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial U} = (A \\odot (UV^T - X))V + 2\\lambda U\\\\\n",
    "\\frac{\\partial J}{\\partial V} = (A \\odot (UV^T - X))^TU + 2\\lambda V\n",
    "$$\n",
    "\n",
    "所以整个算法的流程为：\n",
    "\n",
    "1. 初始化 $U, V$ 为较小的随机值\n",
    "2. 不断循环 $U = U - \\alpha \\frac{\\partial J}{\\partial U}, V = V - \\alpha \\frac{\\partial J}{\\partial V}$，直到收敛\n",
    "\n",
    "上述过程中 $\\alpha$ 为学习率，一般取值为 [0.0001, 0.1] 之间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 10, loss=5150756.7619, 0.3s/epoch.\n",
      "Iter: 20, loss=3677138.7559, 0.2s/epoch.\n",
      "Iter: 30, loss=3328562.5377, 0.2s/epoch.\n",
      "Iter: 40, loss=3176529.8730, 0.2s/epoch.\n",
      "Iter: 50, loss=3093117.5543, 0.2s/epoch.\n",
      "Iter: 60, loss=3040779.8143, 0.2s/epoch.\n",
      "Iter: 70, loss=3004176.7839, 0.2s/epoch.\n",
      "Iter: 80, loss=2975214.4852, 0.2s/epoch.\n",
      "Iter: 90, loss=2948113.7022, 0.2s/epoch.\n",
      "Iter: 100, loss=2917469.2723, 0.2s/epoch.\n",
      "Iter: 110, loss=2880248.3322, 0.2s/epoch.\n",
      "Done in 23.47s.\n",
      "rmse_sp took 0.09s.\n",
      "RMSE: 1.12383.\n"
     ]
    }
   ],
   "source": [
    "cp.cuda.Device(3).use()\n",
    "\n",
    "def init_matrix(X, k, init='random', n_features=10000, n_samples=10000,\n",
    "                seed=1234):\n",
    "    if init == 'random':\n",
    "        # 初始化也很重要\n",
    "        avg = np.sqrt(X.mean() / k)\n",
    "#         print(f'avg={avg}')\n",
    "        rng = np.random.RandomState(seed)\n",
    "        V = avg * rng.randn(k, n_features).astype(X.dtype, copy=False)\n",
    "        U = avg * rng.randn(n_samples, k).astype(X.dtype, copy=False)\n",
    "        np.abs(U, out=U)\n",
    "        np.abs(V, out=V)\n",
    "        return cp.array(U), cp.array(V)\n",
    "    elif init == 'nndsvd':\n",
    "        # https://github.com/scikit-learn/scikit-learn/blob/0fb307bf3/sklearn/decomposition/_nmf.py#L1082\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception('unexcepted init method')\n",
    "\n",
    "def frobenius_norm_sq(X):\n",
    "    norm = cp.sum(cp.power(X, 2))\n",
    "    return norm\n",
    "    \n",
    "def objective(diff, U, V, lamb):\n",
    "    loss = frobenius_norm_sq(diff)\n",
    "    loss = 0.5 * loss + (frobenius_norm_sq(U) + frobenius_norm_sq(V)) * lamb\n",
    "    return loss.item()\n",
    "\n",
    "def fit(X, k, lamb, alpha=1e-3, tol=1e-4, max_iter=500):\n",
    "    st_fit = time()\n",
    "    U, V = init_matrix(X, k)\n",
    "    A = X.copy()\n",
    "    A = A.astype(np.bool)\n",
    "    A = cp.array(A)\n",
    "    X = cp.array(X)\n",
    "    prev_error = 0.\n",
    "    for n_iter in range(1, max_iter + 1):\n",
    "#         print(f'norm(U)={frobenius_norm_sq(U)}, norm(V)={frobenius_norm_sq(V)}')\n",
    "        diff = A * (U @ V - X)\n",
    "        # 因为我这里实现的 V 是老师给的公式中的 V.T 所以会有一点不一样。\n",
    "        update_U = diff @ V.T + 2 * lamb * U\n",
    "        update_V = U.T @ diff + 2 * lamb * V\n",
    "        error = objective(-diff, U, V, lamb)\n",
    "        if n_iter % 10 == 0:\n",
    "            print(f'Iter: {n_iter}, loss={error:.4f}, ' +\n",
    "                  f'{(time() - st_fit) / n_iter:.1f}s/epoch.')\n",
    "        if prev_error != 0 and (prev_error - error) / prev_error <= tol:\n",
    "            break\n",
    "        prev_error = error\n",
    "        U = U - alpha * update_U\n",
    "        V = V - alpha * update_V\n",
    "    X_new = U @ V\n",
    "    return X_new\n",
    "\n",
    "st = time()\n",
    "# 学习率太高很容易导致梯度爆炸\n",
    "X_hat = fit(X_train, k=20, lamb=1, alpha=1e-4, max_iter=200)\n",
    "print(f'Done in {time() - st:.2f}s.')\n",
    "rmse = rmse_cuda(cp.array(X_test), X_hat)\n",
    "print(f'RMSE: {rmse:.5f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 13 23:22:40 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 455.23.04    Driver Version: 455.23.04    CUDA Version: 11.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:18:00.0 Off |                  N/A |\r\n",
      "| 22%   30C    P8    17W / 250W |      3MiB / 11019MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:3B:00.0 Off |                  N/A |\r\n",
      "| 22%   39C    P2    63W / 250W |   5021MiB / 11019MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:86:00.0 Off |                  N/A |\r\n",
      "| 22%   29C    P8    19W / 250W |      3MiB / 11019MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:AF:00.0 Off |                  N/A |\r\n",
      "| 28%   51C    P2    90W / 250W |   1772MiB / 11019MiB |     65%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     21057      C   ...nda3/envs/cupy/bin/python        0MiB |\r\n",
      "|    1   N/A  N/A     21057      C   ...nda3/envs/cupy/bin/python        0MiB |\r\n",
      "|    1   N/A  N/A     23276      C   python                           2561MiB |\r\n",
      "|    1   N/A  N/A     23589      C   python                           2457MiB |\r\n",
      "|    2   N/A  N/A     21057      C   ...nda3/envs/cupy/bin/python        0MiB |\r\n",
      "|    3   N/A  N/A     21057      C   ...nda3/envs/cupy/bin/python     1767MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
