% !TeX encoding = UTF-8
% !TeX program = xelatex
% !TeX spellcheck = en_US

\documentclass[degree=project, degree-type=project]{thuthesis}
\usepackage{mathtools}
% Syntax Highlighting in LaTeX, need pygments
% Must build with xelatex -shell-escape -enable-8bit-chars.
\usepackage{minted}
% https://tex.stackexchange.com/a/112573
\usepackage{tcolorbox}
\usepackage{etoolbox}
\BeforeBeginEnvironment{minted}{\begin{tcolorbox}}%
\AfterEndEnvironment{minted}{\end{tcolorbox}}%
% color for minted
\definecolor{friendlybg}{HTML}{f0f0f0}


% 论文基本配置，加载宏包等全局配置
\thusetup{
    output = electronic,
    title  = {实验二：基于HMM的语音识别实验},
    author  = {肖文韬},
    studentid = {2020214245},
    course = {语音信号数字处理},
    include-spine = false,
}

\usepackage{float}
\usepackage[sort]{natbib}
\bibliographystyle{thuthesis-numeric}
\graphicspath{{figures/}}


\begin{document}

% 封面
\maketitle

\frontmatter
% \input{data/abstract}

% 目录
\tableofcontents

% 插图和附表清单
\listoffigures           % 插图清单

% 正文部分
\mainmatter

\chapter{任务一：Viterbi 解码算法实现}

Forward 和 Backward 算法对应于讲义中的 Q1 (Evaluation)，Vertibi 算法对应于讲义中的 Q2 (Decoding)。
代码实现可以使用 \texttt{sanity\_grader\_hmm()} 测试是否正确。
算法的核心思路及实现如下：

\section{Forward 算法}
  输入：

  \begin{enumerate}
    \item $O$: observations
    \item $\pi$: initial probability
    \item $A$: hidden state transition matrix
    \item $B$: emission matrix
  \end{enumerate}

  输出：

  \begin{align}
    \begin{split}
      P(O | \lambda) &= \sum_{Q} P(O, Q | \lambda) \\
      &= \sum_Q P(O | Q, \lambda) P(Q | \lambda) \\
      &= \sum_Q \prod_{t=1}^T B(q_t, o_t) \pi(q_1) \prod_{t=2}^T A(q_{t-1}, q_t)
    \end{split}
    \label{algo_fwd}
  \end{align}

  公式 \ref{algo_fwd} 可以转换成矩阵运算：

  \begin{align}
    \begin{split}
      \pi^{(0)} &= \pi \\
      \text{Fwd}(o_1) &= \pi^{(1)} = \pi^{(0)} * B(:, o_1), P(o_1) = sum(\text{Fwd}(o_1)) \\
      &\vdots \\
      \text{Fwd}(o_1, \cdots, o_T) &= \pi^{(T)} = \pi^{(T-1)} * B(:, o_T) \\
      P(o_1, \cdots, o_T) &= sum(\text{Fwd}(o_1. \cdots, o_T))
    \end{split}
  \end{align}

  算法复杂度：$O(T * N^2)$

  实现代码：

  \begin{minted}[texcomments,tabsize=2,fontsize=\large,style=friendly,bgcolor=friendlybg]{python}
for t, o_t in enumerate(ob):
  fwd[t] = pi_t * B[:, o_t]
  pi_t = fwd[t] @ A
  \end{minted}


\section{Backward 算法}

Backward 算法目标与 Forward 一样，只不过迭代顺序是从后往前。
代码：

  \begin{minted}[texcomments,tabsize=2,fontsize=\large,style=friendly,bgcolor=friendlybg]{python}
beta_t = np.ones(total_states)
for t, o_t in enumerate(reversed(ob)):
  bwd[-1-t] = beta_t.T
  beta_t = A @ (B[:, o_t] * beta_t)
  \end{minted}

\section{Viterbi 算法}

目标：

启发式搜索 $Q^* = \arg \max_Q P(Q | O, \lambda)$：

\begin{align}
  \begin{split}
    Q^* &= \arg \max_Q P(Q | O, \lambda) \\
    &= \arg \max_Q P(Q, O | \lambda) / P(O | \lambda) \\
    &= \arg \max_Q P(Q, O | \lambda) \\
    &= \arg \max_Q P(O | Q, \lambda) P(Q | \lambda) \\
    &= \arg \max_Q \prod_{t=1}^T B(q_t, o_t) \pi(q_1) \prod_{t=2}^T A(q_{t-1}, q_t)
  \end{split}
  \label{algo_viterbi}
\end{align}

同样地，类似 Forward 算法，上式 \ref{algo_viterbi} 可以优化为迭代形式：

\begin{equation}
\delta_t (j) = \arg \max_{q_1, q_2, \cdots, q_{t-1}} P(q_1, \cdots, q_{t-1}, q_t=s_j, o_1, \cdots, o_t | \lambda)
\end{equation}

初始化：

\begin{equation}
  \delta_1 = \pi * B(:, o_1)
\end{equation}

递推式：

\begin{align}
  \begin{split}
    \phi_t &= \arg \max(\delta_{t-1} \odot A^T, \text{axis}=1) \\
    \delta_t &= \max(\delta_{t-1} \odot A^T, \text{axis}=1) * B(:, o_t)
  \end{split}
\end{align}

代码实现：

  \begin{minted}[texcomments,tabsize=2,fontsize=\large,style=friendly,bgcolor=friendlybg]{python}
delta_t = pi
phi_t = np.zeros(total_states)
for t, o_t in enumerate(ob):
  delta_t *= B[:, o_t]
  delta[t] = delta_t
  phi[t] = phi_t
  phi_t = np.argmax(delta_t * A.T, axis=1)
  delta_t = np.max(delta_t * A.T, axis=1)
  \end{minted}

\chapter{任务二：基于 GMM-HMM 的语音识别}

\section{Q1 ($3"$)}

Q: Look at the directory data/train, describe what is contained in files text, wav.scp and utt2spk respectively (Hint: all those files can be seen as key-value dicts).

A:

\begin{enumerate}
  \item text: 每一行地第一个元素是 utterance-id，可以为任意字符串。后面的部分就是每一句的录音对应的文本（字幕），如果有词不在字典中（out of vocabulary），将会自动映射到 data/lang/oov.txt 中指定的词。
  \item wav.scp:格式为 \texttt{<recording-id> <extended-filename>}，extended-filename 可以为音频文件，也可以是能够返回出 wav 音频文件的任意命令。如果不存在 segments 文件，recording-id 就会自动用作 utterance-id。
  \item utt2sp: 每一行的格式为 \texttt{<utterance-id> <speaker-id>}，用于标识每一个发音对应的发音者（speaker）。
\end{enumerate}

需要注意的有：

\begin{enumerate}
  \item 这些文件中的顺序需要对应起来
  \item wav.scp 中的音频文件必须是单通道的，否则需要用 sox 命令提取出指定的 channel。
  \item utterance-id, speaker-id 都推荐各自使用固定长度，否则可能回导致 C-style string order 出问题。
\end{enumerate}

\section{Q2 ($3"$)}

Q: Look at the file data/lang/topo, which contains two kinds of HMM topology, draw them using circles and arrows like this. You may notice that the HMM topology of a special phoneme is different from other phonemes. Use data/lang/phones.txt to map and find the name of the special phoneme.

A: 

\section{Q3 ($2"$)}

Q: You can change num-sil-states and num-nonsil-states for command utils/prepare\_lang.sh in run.sh, then run this stage again and draw new topologies from data/lang/topo. (Note that set them to default values(sil=3 and nonsil=3) and rerun this stage before proceeding to the next stage since other values may affect the performance).

\chapter{任务三：基于 DNN-HMM 的语音识别}

% 其他部分
\backmatter

% 参考文献
\bibliography{ref/refs}  % 参考文献使用 BibTeX 编译

% 附录
\appendix
\end{document}
